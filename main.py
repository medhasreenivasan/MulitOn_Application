
import cv2
import os
import torch
from lavis.models import load_model_and_preprocess
from openai import OpenAI
from PIL import Image
import re
from multion.client import MultiOn
from typing import Union

from fastapi import FastAPI, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
import nest_asyncio
from pyngrok import ngrok,conf
import uvicorn


## Authorize all tokens
multion = MultiOn(api_key="MULTION_API_KEY")
conf.get_default().auth_token = "NGROK_AUTH_TOKEN"
client = OpenAI(api_key="OPENAI_API_KEY")


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

## Download the model tensors																						 
model, vis_processors, _ = load_model_and_preprocess(
    name="blip_caption", model_type="base_coco", is_eval=True, device=device)


def complete(prompt):
    """
    Generates a completion for the given prompt using the OpenAI chat API.

    Args:
        prompt (str): The prompt to be completed.

    Returns:
        str: The completion generated by the OpenAI chat API.
    """
    chat_completion = client.chat.completions.create(
        messages=[		 				   
            {"role": "user", "content": prompt}	 
        ],
        model="gpt-3.5-turbo-0125",
    )
    return chat_completion.choices[0].message.content.strip()

async def get_visual_prompt_async(visual):
    """
    Generates the image caption prompt based on the visual input asynchronously.

    Args:
        visual (PIL.Image.Image): The input visual image.

    Returns:
        str: The image caption prompt generated based on the visual input.
    """
    image = vis_processors["eval"](visual).unsqueeze(0).to(device)
    visual_prompt = model.generate({"image": image})[0]
    return visual_prompt

async def complete_prompt(visual_prompt, user_input):
    PROMPT = """You are an AI that can understand images and make deep analyis base on
    the visual description of current scenario.
    You can place orders online. You can also help writing creative things, like jokes, and poems.

    Example:
    Visual: An image of Kung Pao Chicken.
    Human: Order this food from doordash
    AI: Sure, I can do it for you. [order kung pao chicken from doordash]

                                                    

      

    Decode in the following format:
    Visual: ...
    Human: ...
    AI: ...
                    
                
                          
                    

    Order food can be done with something like [order <item> from Amazon], one action square bracket.

    [eot]

    """
    PROMPT += f'Visual: {visual_prompt}\n'
    PROMPT += f'Human:{input}\nAI:'
    gpt_results = complete(PROMPT).strip()

    if len(gpt_results) > 1:
      visual_prompt = gpt_results[1].strip()
    response = (input, gpt_results)

    return response

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=['*'],
    allow_credentials=True,
    allow_methods=['*'],
    allow_headers=['*'],
)


@app.post("/get_visual_prompt")
async def get_visual_prompt(image: UploadFile = File(...), user_input: str = Form(...)):
						  
    img = Image.open(image.file).convert("RGB")
    visual_prompt = await get_visual_prompt_async(img)
    complete_visual_prompt = await complete_prompt(visual_prompt, user_input)
    pattern = r'\[([^\[\]]+)\]'
    input_command = re.findall(pattern, complete_visual_prompt[1])
    browse = multion.browse(cmd=input_command[0], local=True) if input_command else f"Input command not generated: {complete_visual_prompt}, {visual_prompt}"
    return {"browse": browse}

ngrok_tunnel = ngrok.connect(8000)
print('Public URL:', ngrok_tunnel.public_url)
nest_asyncio.apply()
uvicorn.run(app, port=8000)
